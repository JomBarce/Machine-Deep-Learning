{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5569ebe-d9bb-4017-a5d6-fd7b87c8307b",
   "metadata": {},
   "source": [
    "# LDA DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b481af9-3e7a-4407-8bde-8d01b5d3b738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import spacy\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "\n",
    "# Load spaCy's English NLP model\n",
    "nlp = spacy.load('en_core_web_sm')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56591d37-365b-4b44-b0a2-f00900104823",
   "metadata": {},
   "source": [
    "# Sample documents for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72f3c3a-5ca9-4272-8d27-c5af9b0754c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Document\n",
    "old_documents = [\n",
    "    \"Natural language processing is a subfield of artificial intelligence.\",\n",
    "    \"Latent Dirichlet Allocation is a generative probabilistic model.\",\n",
    "    \"Topic modeling is used to identify topics present in a corpus of text.\",\n",
    "    \"Gensim is a popular Python library for topic modeling and document similarity.\"\n",
    "]\n",
    "\n",
    "# New Sample Documents\n",
    "documents = [\n",
    "    \"Artificial intelligence is reshaping industries and revolutionizing technology.\",\n",
    "    \"Unsupervised learning methods, such as clustering, play a pivotal role in data analysis.\",\n",
    "    \"The intersection of data science and business strategy is driving innovation.\",\n",
    "    \"Natural language processing enables machines to understand and interpret human language.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b04ad12-95ea-4a0a-ac49-f4ee9fbaeee2",
   "metadata": {},
   "source": [
    "# Preprocess the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a97f87a2-a9f4-4557-aef6-c921bda4e2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(text):\n",
    "    # Tokenize and lemmatize using spaCy\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_ for token in doc if not token.is_stop and token.is_alpha]\n",
    "    return tokens\n",
    "\n",
    "# Apply preprocessing to all documents\n",
    "processed_documents = [preprocess(doc) for doc in documents]\n",
    "\n",
    "# Create a dictionary and corpus for LDA\n",
    "dictionary = corpora.Dictionary(processed_documents)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in processed_documents]\n",
    "\n",
    "# Build LDA model (3, 5, 7)\n",
    "lda_model_3 = gensim.models.LdaModel(corpus, num_topics=3, id2word=dictionary, passes=15)\n",
    "lda_model_5 = gensim.models.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=15)\n",
    "lda_model_7 = gensim.models.LdaModel(corpus, num_topics=7, id2word=dictionary, passes=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05542fa2-2765-4327-bb81-27e6b2d629ef",
   "metadata": {},
   "source": [
    "# Print topics and their keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f567bec-dfdf-4dd8-80b3-169eb11aa978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 Topics\n",
      "[(0,\n",
      "  '0.051*\"method\" + 0.051*\"role\" + 0.051*\"pivotal\" + 0.051*\"analysis\" + '\n",
      "  '0.051*\"data\" + 0.051*\"clustering\" + 0.051*\"play\" + 0.051*\"learning\" + '\n",
      "  '0.051*\"unsupervised\" + 0.051*\"datum\"'),\n",
      " (1,\n",
      "  '0.083*\"technology\" + 0.083*\"intelligence\" + 0.083*\"industry\" + '\n",
      "  '0.083*\"artificial\" + 0.083*\"revolutionize\" + 0.083*\"reshape\" + '\n",
      "  '0.021*\"language\" + 0.021*\"strategy\" + 0.021*\"drive\" + 0.021*\"science\"'),\n",
      " (2,\n",
      "  '0.123*\"language\" + 0.070*\"enable\" + 0.070*\"understand\" + 0.070*\"natural\" + '\n",
      "  '0.070*\"machine\" + 0.070*\"interpret\" + 0.070*\"processing\" + 0.070*\"human\" + '\n",
      "  '0.018*\"strategy\" + 0.018*\"drive\"')]\n"
     ]
    }
   ],
   "source": [
    "# 3 Topics\n",
    "print('3 Topics')\n",
    "pprint(lda_model_3.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 Topics\n",
      "[(0,\n",
      "  '0.147*\"language\" + 0.080*\"human\" + 0.080*\"processing\" + 0.080*\"natural\" + '\n",
      "  '0.080*\"understand\" + 0.080*\"enable\" + 0.080*\"machine\" + 0.080*\"interpret\" + '\n",
      "  '0.013*\"industry\" + 0.013*\"reshape\"'),\n",
      " (1,\n",
      "  '0.080*\"play\" + 0.080*\"method\" + 0.080*\"role\" + 0.080*\"clustering\" + '\n",
      "  '0.080*\"pivotal\" + 0.080*\"data\" + 0.080*\"learning\" + 0.080*\"analysis\" + '\n",
      "  '0.080*\"unsupervised\" + 0.013*\"artificial\"'),\n",
      " (2,\n",
      "  '0.100*\"intelligence\" + 0.100*\"artificial\" + 0.100*\"technology\" + '\n",
      "  '0.100*\"revolutionize\" + 0.100*\"industry\" + 0.100*\"reshape\" + '\n",
      "  '0.017*\"strategy\" + 0.017*\"science\" + 0.017*\"datum\" + 0.017*\"business\"'),\n",
      " (3,\n",
      "  '0.033*\"industry\" + 0.033*\"reshape\" + 0.033*\"technology\" + '\n",
      "  '0.033*\"revolutionize\" + 0.033*\"intelligence\" + 0.033*\"artificial\" + '\n",
      "  '0.033*\"science\" + 0.033*\"business\" + 0.033*\"strategy\" + 0.033*\"datum\"'),\n",
      " (4,\n",
      "  '0.092*\"datum\" + 0.092*\"intersection\" + 0.092*\"drive\" + 0.092*\"innovation\" + '\n",
      "  '0.092*\"strategy\" + 0.092*\"business\" + 0.092*\"science\" + 0.015*\"reshape\" + '\n",
      "  '0.015*\"revolutionize\" + 0.015*\"industry\"')]\n"
     ]
    }
   ],
   "source": [
    "# 5 Topics\n",
    "print('5 Topics')\n",
    "pprint(lda_model_5.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 Topics\n",
      "[(0,\n",
      "  '0.033*\"technology\" + 0.033*\"artificial\" + 0.033*\"datum\" + 0.033*\"reshape\" + '\n",
      "  '0.033*\"intelligence\" + 0.033*\"intersection\" + 0.033*\"strategy\" + '\n",
      "  '0.033*\"science\" + 0.033*\"industry\" + 0.033*\"interpret\"'),\n",
      " (1,\n",
      "  '0.161*\"language\" + 0.086*\"enable\" + 0.086*\"natural\" + 0.086*\"human\" + '\n",
      "  '0.086*\"interpret\" + 0.086*\"processing\" + 0.086*\"machine\" + '\n",
      "  '0.086*\"understand\" + 0.011*\"industry\" + 0.011*\"intelligence\"'),\n",
      " (2,\n",
      "  '0.033*\"reshape\" + 0.033*\"industry\" + 0.033*\"intersection\" + '\n",
      "  '0.033*\"revolutionize\" + 0.033*\"technology\" + 0.033*\"artificial\" + '\n",
      "  '0.033*\"datum\" + 0.033*\"language\" + 0.033*\"science\" + 0.033*\"innovation\"'),\n",
      " (3,\n",
      "  '0.033*\"reshape\" + 0.033*\"science\" + 0.033*\"industry\" + 0.033*\"language\" + '\n",
      "  '0.033*\"intelligence\" + 0.033*\"artificial\" + 0.033*\"drive\" + '\n",
      "  '0.033*\"innovation\" + 0.033*\"datum\" + 0.033*\"interpret\"'),\n",
      " (4,\n",
      "  '0.086*\"method\" + 0.086*\"role\" + 0.086*\"analysis\" + 0.086*\"clustering\" + '\n",
      "  '0.086*\"play\" + 0.086*\"pivotal\" + 0.086*\"data\" + 0.086*\"learning\" + '\n",
      "  '0.086*\"unsupervised\" + 0.011*\"industry\"'),\n",
      " (5,\n",
      "  '0.101*\"intersection\" + 0.101*\"business\" + 0.101*\"drive\" + 0.101*\"datum\" + '\n",
      "  '0.101*\"strategy\" + 0.101*\"innovation\" + 0.101*\"science\" + 0.013*\"industry\" '\n",
      "  '+ 0.013*\"reshape\" + 0.013*\"understand\"'),\n",
      " (6,\n",
      "  '0.111*\"revolutionize\" + 0.111*\"intelligence\" + 0.111*\"technology\" + '\n",
      "  '0.111*\"artificial\" + 0.111*\"industry\" + 0.111*\"reshape\" + 0.014*\"language\" '\n",
      "  '+ 0.014*\"innovation\" + 0.014*\"datum\" + 0.014*\"science\"')]\n"
     ]
    }
   ],
   "source": [
    "# 7 Topics\n",
    "print('7 Topics')\n",
    "pprint(lda_model_7.print_topics())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7bc7e95-7c82-4bcd-994e-caf4d5498317",
   "metadata": {},
   "source": [
    "0 -- Gensim lib\n",
    "1 -- python prog, LDA\n",
    "2 -- NLP\n",
    "\n",
    "  1- \"Natural language processing is a subfield of artificial intelligence.\",\n",
    "   2 \"Latent Dirichlet Allocation is a generative probabilistic model.\",\n",
    "   3 \"Topic modeling is used to identify topics present in a corpus of text.\",\n",
    "   4 \"Gensim is a popular Python library for topic modeling and document similarity.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000de19a-8dd4-40e5-966b-25442d67ce78",
   "metadata": {},
   "source": [
    "# Assign topics to documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da343547-03b4-41b6-b1b6-1faba58a87a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Topic: [(0, 0.047816664), (1, 0.9042901), (2, 0.047893275)]\n",
      "Document 2 - Topic: [(0, 0.9326373), (1, 0.033713274), (2, 0.033649497)]\n",
      "Document 3 - Topic: [(0, 0.91579074), (1, 0.042144798), (2, 0.04206447)]\n",
      "Document 4 - Topic: [(0, 0.033477753), (1, 0.033574242), (2, 0.932948)]\n"
     ]
    }
   ],
   "source": [
    "# Assign topics to documents - 3 Topics\n",
    "for i, doc in enumerate(processed_documents):\n",
    "    print(f\"Document {i+1} - Topic: {lda_model_3.get_document_topics(corpus[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Topic: [(0, 0.02857554), (1, 0.02857554), (2, 0.88569045), (3, 0.028582249), (4, 0.02857619)]\n",
      "Document 2 - Topic: [(0, 0.020003576), (1, 0.91997826), (2, 0.0200045), (3, 0.020009542), (4, 0.02000414)]\n",
      "Document 3 - Topic: [(0, 0.025003882), (1, 0.025003882), (2, 0.025004886), (3, 0.025010284), (4, 0.8999771)]\n",
      "Document 4 - Topic: [(0, 0.91998106), (1, 0.020003125), (2, 0.020003935), (3, 0.02000827), (4, 0.02000362)]\n"
     ]
    }
   ],
   "source": [
    "# Assign topics to documents - 5 Topics\n",
    "for i, doc in enumerate(processed_documents):\n",
    "    print(f\"Document {i+1} - Topic: {lda_model_5.get_document_topics(corpus[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 - Topic: [(0, 0.020408424), (1, 0.020408265), (2, 0.020408424), (3, 0.020408424), (4, 0.020408265), (5, 0.020408276), (6, 0.87754995)]\n",
      "Document 2 - Topic: [(0, 0.01428595), (1, 0.0142858075), (2, 0.01428595), (3, 0.01428595), (4, 0.9142847), (5, 0.01428582), (6, 0.014285827)]\n",
      "Document 3 - Topic: [(0, 0.017857391), (1, 0.017857239), (2, 0.017857391), (3, 0.017857391), (4, 0.017857239), (5, 0.8928561), (6, 0.01785726)]\n",
      "Document 4 - Topic: [(0, 0.014285918), (1, 0.9142848), (2, 0.014285918), (3, 0.014285918), (4, 0.014285794), (5, 0.014285805), (6, 0.01428581)]\n"
     ]
    }
   ],
   "source": [
    "# Assign topics to documents - 7 Topics\n",
    "for i, doc in enumerate(processed_documents):\n",
    "    print(f\"Document {i+1} - Topic: {lda_model_7.get_document_topics(corpus[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17631d05-4439-4d2d-a59a-fe43b98bf5f9",
   "metadata": {},
   "source": [
    "#                   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbf91b0-fe18-489a-a7f4-d97b0b4c1eed",
   "metadata": {},
   "source": [
    "# Mini Exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bad36b-18ab-422e-a1ce-c23b2254a9af",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "Use the provided Python code to perform topic modeling on a set of sample documents.\n",
    "Modify the sample documents or add your own to see how the results change.\n",
    "Experiment with the number of topics (parameter: num_topics) in the LDA model. Observe how different numbers of topics impact the result\n",
    "\n",
    "Make a small insight on what you have observe when you change, increase, or decrease some parameters.(Short Essay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Varying the number of topics (num_topics) in the Latent Dirichlet Allocation (LDA) model experimentation for topic modeling yielded intriguing findings. The model appeared to be able to pick up on subtleties and finer details in the documents as the number of topics increased, which resulted in more focused themes. However, reducing the number of topics resulted in broader and more generalized categories. Finding a balance was important since too few topics oversimplified the representation and too many topics ran the danger of overfitting. This subtle tweaking of the parameters made it possible to use atailored approach in uncovering the latent structure in the text data, highlighting the significance of parameter tuning in maximizing the efficiency of topic modeling algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
